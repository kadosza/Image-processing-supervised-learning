{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "# Read the csv files:\n",
    "mnist_train = pd.read_csv('mnist_train.csv')\n",
    "mnist_test = pd.read_csv('mnist_test.csv')\n",
    "\n",
    "# Print data shapes:\n",
    "print(mnist_train.shape)\n",
    "print(mnist_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set represents 14.28% of all the pictures in both train and test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables for train set:\n",
    "y_train = mnist_train.iloc[:, 0].values\n",
    "x_train = mnist_train.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables for test set:\n",
    "y_test = mnist_test.iloc[:, 0]\n",
    "x_test = mnist_test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the train set into train and development sets by using train_test_split funciton into train 80% and development 20% set:\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train, test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the three data sets:\n",
    "- train data set - will be used to create/train initial Random Forest model. It will also be used later on, once the parameters are tuned for the model.\n",
    "- development (test) data set - will be used to test the initial training (get the initial accuracy score for the model before parameters are tuned). It will also be used as a portion of data to test various parameters settings for the model\n",
    "- test (validation) data set - will be used to test the tuned model on the unseen portion of data, and to calculate final precision, recall, f1, accuracy scores and visualise confusion matrix, to see how well the model predicted the values compared with the actual test values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ensemble forest on dev data: 0.858\n"
     ]
    }
   ],
   "source": [
    "# Build Random Forest classification model: \n",
    "ensemble_forest = RandomForestClassifier(max_depth = 5, n_estimators=100, random_state=5)\n",
    "ensemble_forest.fit(x_train, y_train)\n",
    "\n",
    "# Predict the model on dev set:\n",
    "y_pred_dev = ensemble_forest.predict(x_dev)\n",
    "\n",
    "# Get accuracy of the model performance on dev data:\n",
    "accuracy_dev = ensemble_forest.score(x_dev, y_dev)\n",
    "print(\"Accuracy of ensemble forest on dev data:\", round(accuracy_dev,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest accuracy score at 2 max_depth:\t 0.645\n",
      "Forest accuracy score at 3 max_depth:\t 0.752\n",
      "Forest accuracy score at 4 max_depth:\t 0.811\n",
      "Forest accuracy score at 5 max_depth:\t 0.866\n",
      "Forest accuracy score at 6 max_depth:\t 0.9\n",
      "Forest accuracy score at 7 max_depth:\t 0.928\n",
      "Forest accuracy score at 8 max_depth:\t 0.952\n",
      "Forest accuracy score at 9 max_depth:\t 0.97\n",
      "Forest accuracy score at 10 max_depth:\t 0.985\n"
     ]
    }
   ],
   "source": [
    "# The parameter I chose to tune is max_depth. This indicates how deep the tree can be (the deeper, the more splits it has and captures more information). \n",
    "# I assessed the number of max_depths in Random Forest model looking at the accuracy score for each max_depth (range 2-10) using development data:\n",
    "for x in range(2,11):\n",
    "    max_depth = x\n",
    "    ensemble_forest = RandomForestClassifier(max_depth = max_depth, n_estimators=100, random_state=5).fit(x_dev, y_dev)\n",
    "    print(f\"Forest accuracy score at {max_depth} max_depth:\\t\", round(ensemble_forest.score(x_dev, y_dev),3))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth of 10 produced the highest accuracy, so I will use it in my model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Forest at 1 estimations:\t 0.818\n",
      "Accuracy Forest at 3 estimations:\t 0.919\n",
      "Accuracy Forest at 5 estimations:\t 0.949\n",
      "Accuracy Forest at 10 estimations:\t 0.97\n",
      "Accuracy Forest at 20 estimations:\t 0.978\n",
      "Accuracy Forest at 50 estimations:\t 0.984\n",
      "Accuracy Forest at 100 estimations:\t 0.985\n",
      "Accuracy Forest at 150 estimations:\t 0.986\n",
      "Accuracy Forest at 200 estimations:\t 0.986\n"
     ]
    }
   ],
   "source": [
    "# I also looked at the number of n_estimators in Random Forest model on the accuracy score using dev data: \n",
    "for x in (1,3,5,10,20,50,100,150,200):\n",
    "    estimations = x\n",
    "    ensemble_forest = RandomForestClassifier(max_depth = 10, n_estimators=estimations, random_state=5).fit(x_dev, y_dev)\n",
    "    print(f\"Accuracy Forest at {estimations} estimations:\\t\", round(ensemble_forest.score(x_dev, y_dev),3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators of 100, chosen at the beginning, works ok here, so I will keep using this value in my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bdzie\\anaconda3\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>968</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1120</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>964</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>941</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>920</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>826</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>945</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>904</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1    2    3    4    5    6    7    8    9\n",
       "0  968     1    0    0    0    2    4    1    3    1\n",
       "1    0  1120    4    3    0    1    3    1    3    0\n",
       "2    9     1  964   11   13    0    7   15   10    2\n",
       "3    1     0   15  941    1   19    0   14   15    4\n",
       "4    1     0    1    0  920    0    8    1    8   43\n",
       "5    6     6    3   20    6  826    8    3    7    7\n",
       "6    8     4    0    0    6    9  925    0    5    1\n",
       "7    2     7   28    3    4    0    0  945    5   34\n",
       "8    3     1    6   12    7    8    6    4  904   23\n",
       "9    8     7    0   14   17    4    1    5   12  941"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Random Forest Model predictions on test data:\n",
    "ensemble_forest = RandomForestClassifier(max_depth = 10, n_estimators=100, random_state=5)\n",
    "ensemble_forest.fit(x_train, y_train)\n",
    "y_pred_test = ensemble_forest.predict(x_test)\n",
    "\n",
    "# Creating and visualizing confusion matrix for my Random Forest model on the test set:\n",
    "conf_mat = confusion_matrix(y_test,y_pred_test)\n",
    "conf_mat_df = pd.DataFrame(conf_mat)\n",
    "conf_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97482377 0.98159509 0.93911349 0.93445879 0.9406953  0.93810335\n",
      " 0.96354167 0.9370352  0.9290853  0.91138015]\n",
      "Hardest class to identify: 9\n"
     ]
    }
   ],
   "source": [
    "# Which classes the model struggled most?\n",
    "\n",
    "# Getting the conf_mat data frame labels:\n",
    "classes = conf_mat_df.columns\n",
    "\n",
    "# f1 score per feature tells us which were most difficult to identify:\n",
    "f = f1_score(y_test, y_pred_test, average = None)\n",
    "print(f)\n",
    "lowest_score = min(f)\n",
    "hardest_class = classes[list(f).index(lowest_score)]\n",
    "print('Hardest class to identify:', hardest_class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hardest to identify was number 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9454\n",
      "Precision: 0.9454\n",
      "Recall: 0.9454\n",
      "f1 score: 0.945\n"
     ]
    }
   ],
   "source": [
    "# Accuracy, precision, recall and f1 scores for the predicted model: \n",
    "accur_score = accuracy_score(y_test, y_pred_test)\n",
    "print('Accuracy: ',accur_score)\n",
    "\n",
    "prec_score = precision_score(y_test, y_pred_test, average = \"micro\")\n",
    "print('Precision:', prec_score)\n",
    "\n",
    "rec_score = recall_score(y_test, y_pred_test, average = \"micro\")\n",
    "print('Recall:', rec_score)\n",
    "\n",
    "average_f1 = f1_score(y_test, y_pred_test, average='micro')\n",
    "print('f1 score:', round(average_f1,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores are the same becuase are based on the weighted average for each."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b35ba4b709a2350bd2a9138495f0fac1b13ff7a023e4ca3e11d8d3ef473e8ae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
